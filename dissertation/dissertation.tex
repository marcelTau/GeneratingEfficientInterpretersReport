\documentclass{article}
\title{Dissertation}
\author{
    Marcel Taubert  (mt652)\\
    20962335        \\
    \\
    School of Computing \\
    MSc Advanced Computer Science\\
    University of Kent \\
    \\
    Supervisor: Dr. Michael Vollmer
}
\usepackage{natbib,hyperref}
\date{\today}
\begin{document}
\maketitle
\clearpage

\section{Introduction}

%1. Introduction: objectives, intro to contents (overview)
    %- what is a vm interpreter
    %- how does a vm interpreter work
    %- difference between stack and register based vm
    %- what are optimizations, what optimizations are we using
    %- what kind of optimizations are there
    %- code generation (from a config file)
%3. description of the problem
    %- many parts of interpreter writing can be automated 
    %- why should we care about efficieny in interpreter
%6. literature and technology review, (what papers, vmgen??)
    %- what it says and how it relates to my project
%7. possible approaches and reason why we choose this approach
    %- by hand is hard
    %- doing it automatically
    %- what optimizations
    %- why rust not C (why others did it in C, what can you do in C)
    %- why for the Imp programming language
    %- why not compile to C code (2nd paper)
%8. description of work that we did 
    %- vm (stack, why tho)
    %- interpreter (visitor pattern)
    %- parser and scanner (not generated, why)
    %- bytecode design (why and how does it work)
    %- bytecode generator
    %- bytecode interpreter (visitor pattern)
    %- what is the input language
    %- optimizations (superinstructions, computed go-to)
    %- benchmark program
%10. Results: tests, benchmarks, what kind of programs
%11. Summary, Conclusion
%12. future work (automation)
%13. Bibliography

%/*
%What is an interpreter?
%- Programming is everywhere
%- 2 ways how code is run (compiler and interpreter)
%- whats good about interpreters
%*/

In the modern world we live in today, everything is controlled by code.
Everyone of us is using technology controlled by code, if they want it or not.
But not many people know how the code that programmers around the world write
gets executed on their device.


\subsection{What is an interpreter?}
In general there are two ways to execute code. Both approaches include the
process of translating the human readable code into something that the computer
can understand. 

During the first technique the code is compiled (translated) into machine code.
The end product is a stand alone program that can be executed at any time on the
architecture it was compiled for.

The second approach is called 'interpreting'. There are two primary methods
to how an interpreter works. One approach is called a tree-walk interpreter.

In this case the interpreter just walks the generated abstract syntax tree
and executes it.

The second approach is a virtual machine interpreter which involves an extra
step between the generation of the syntax tree and the execution. A compiler
walks the tree and generates byte code. This bytecode will then be fed into
the virtual machine which executes it.

We will use a virtual machine interpreter in this paper.

Interpreters are generally easier to implement and have some other advantages
that makes them more approachable than compilers like portability or a fast
edit-compile-run cycle as stated by the authors of vmgen ~\cite{vmgen}. 

%/*
%what is a vm interpreter?
%- create intermediate representation that is similar to a real machine
%- series of bytecode instructions
%- (Frontend) compiler that produces this bytecode (written in rust)
%- (Backend) vm interpreter that executes the instructions
%- Some examples of vm interpreters (JVM, PVM (python))
%*/

\subsection{What is a virtual machine interpreter?}
A famous technique to implement interpreters is to build a virtual machine
interpreter. A vm interpreter is generally divided into two systems. A frontend
and a backend. ~\cite{vmgen}

The frontend consists of a compiler that takes the written code and produces a
sequence of bytecode instructions. The backend is a virtual machine that gets
the stream of bytecode instructions as input and executes them. ~\cite{vmgen}

The bytecode or intermediate representation used in a vm interpreter is usually
designed to be very similar to a real machine. ~\cite{vmgen}

Some real world examples of virtual machine interpreters are for example the
JVM (Java Virtual Machine) or the PVM (Python Virtual Machine). (TODO: link to them???)


\subsection{Virtual machine}
When we are talking about virtual machines we distinguish between stack based vm's and 
register based vm's.

Each of the version has it's advantages and disadvantages.

Stack based virtual machines are generally easier to implement than the register based approach.
That shows for example in the complexity of the intermediate representation used in the virtual 
machine. The stack based bytecode has a tendency of being smaller and by that more efficient in 
comparison to the rather complex bytecode instructions of the register based approach.

\begin{verbatim}
typical stack based instruction:
Push 1    -- push value to the stack
\end{verbatim}

\begin{verbatim}
typical register based instruction:
LD R1, 42 -- load value `42` into register R1
\end{verbatim}

This simplicity is the reason we have to decided to rely on a stack based virtual machine in
this paper.

\subsection{Optimizations}
When you are running your Java program the compiler does not just generate bytecode for
the JVM from your written code. The compiler will try it's best to optimize as much as possible
to ensure that the execution of the produced bytecode will be as fast as possible.
This optimization part of the compiler is by far one of the most crucial tasks of a compiler.

During the development of this project we have looked at a number of different
optimizations. Some of the optimizations that we have implemented for the
project are threaded code and peephole optimizations (superinstructions) (TODO:
SHOULD I EXPLAIN THEM HERE)


\subsection{Automation}
Writing an interpreter for a programming language can be a tedious and
challenging task on it's own. Thinking about how to keep the code efficient and
additionally implement optimizations makes it even harder.

One solution to this is automating the process of writing a virutal machine interpreter
by providing a configuration file.

\subsection{Objectives}
This paper will use the Rust programming language to build each part of a virtual machine 
interpreter with the optimal goal of automating the generation of it self depending on
a given configuration of a user.

We will explore techniques and approaches on how to build a vm interpreter in Rust and
use benchmarking to visualize results depending on applied optimizations.

\section{Description of the problem}
\subsection{Efficiency}
In terms of efficiency at run time of a program nativ compiled machine code
will always outperform the interpreted version. So why would we even care
about writing efficient interpreters and not just use native code compilers.

One of the main reasons interpreters are preferred over compilers is that 
native code compilers are more complex to develop and difficult to maintain.
~\cite{structure_and_performance}

Another big advantage of the interpreting approach is that compilers can only
generate native code for one target system while the virtual machine
interpreter stays the same on every system. By that the interpreter is portable
and the generated code does not depend on the underlaying machine.

\subsection{Automation}
Many programmers will come to the idea of implementing their own programming
language at some point in their career. Most of them will have noticed that
buidling an interpreter is a challenging task and requires a lot of work and
a clear structure. In addition to that it shows that many parts of an vm
interpreter are similar and repetitive. For example the code for executing 
VM instructions will be similar for most of the instructions. ~\cite{vmgen}

But what happens when the interpreter does not give the expected outcome in
terms of efficiency. It results in manual rewriting of a codebase just to
change the implementation of some part of the vm interpreter to see if the
performance increases.
Rewriting the whole interpreter to test if the performance is better using
a different development approach is not only time consuming but also error 
prone.

One solution to this problem is automation. The user should be able to provide
a configuration file and based on that we will generate an efficient vm 
interpreter. It will already use efficient implementation techniques and come
with built in optimizations. It also provides easy extensibility for the user
without needing to change any source code.

\section{Description of work}
The goal of this project is to build an virtual machine interpreter and 
explore the implementation of such in the Rust programming language.

\subsection{Tools used}
During the development of this project we used three programming languages. We
build the virtual machine and all parts of the interpreter in Rust and used
Python to visualize any benchmarking results. The input language of the
interpreter is the Imp programming language (see section
\ref{sec:input_language}). ~\cite{Pierce:SF1}

But why did we use Rust and not the C programming language like most other
systems do?
One reason for that is that as stated before most of the already existing
solutions are written in C and we wanted to explore something new.
Another reason why we decided to use Rust is that we were looking for a low level
systems programming language that allows us to work as efficient as possible
while still offering high level features like match statements and iterators.
An extension to that is Rust's expressive type system and strict memory
management rules which helps avoiding many kinds of errors that appear in 
standard C programming.

\subsection{Virtual Machine} % stack based, show bytecode, reason about bytecode in rust enum
The virtual machine is the part that exectues the byte code that was generated
by the compiler.

\subsubsection{Implementation}
The virtual machine we have built is very basic. It contains a representation
of the stack and a HashMap to hold the variables.

\begin{verbatim}
pub struct ByteCodeInterpreter {
    stack: Vec<usize>,
    pc: i32,
    variables: HashMap<String, usize>,
}
\end{verbatim}
\textit{ByteCodeInterpreter struct definition} \\

The optimized version of it implementing the `computed goto` optimization (see
section \ref{it:goto}) is a bit more complicated. Here we also have the mapping
of ByteCode to the function that executes this bytecode. This optimization is 
described in more detail at \ref{it:goto}.

\begin{verbatim}
pub struct ByteCodeInterpreterThreaded {
    stack: Vec<usize>,
    pc: i32,
    variables: HashMap<String, usize>,
    ops: HashMap<Discriminant<ByteCode>, Instruction>,
    instructions: Vec<ByteCode>,
}
\end{verbatim}
\textit{ByteCodeInterpreterThreaded struct definition} \\


\subsubsection{Stack}
The virtual machine we built is stack based. This means there are no registers
and everything happens on the stack.

When you add two numbers there will be a `push` instruction for both values
and an add instruction which will pop the last two values from the stack,
adds them together and pushes the result back on the stack.

\begin{verbatim}
The code `1 + 2` would produce the following instructions:

inst:    stack:
         []
push 1   [1]
push 2   [1, 2]
add      [3]
\end{verbatim}

\subsubsection{Byte code}
To define a byte code we have decided to use Rust's powerful enums. They are
not only able to perfectly represent each instruction with it's parameters but
also helps during development due to Rust's powerful type system.

\begin{verbatim}

#[derive(Debug, Clone, PartialEq)]
pub enum ByteCode {
    Push(usize),
    Pop,
    Add,
    Sub,
    Mul,
    Var(String),
    Eq,
    NEq,
    Lt,
    Gt,
    Lte,
    Jz {
        label: String,
        offset: i32,
    },
    ...
}

\end{verbatim}
\textit{Rust representation of the Byte Code} \\

One downside of using the convenient Rust way of using enums to represent byte
code is that they are relatively large in memory.

One byte code instruction adds up to 32 bits in memory. 
Enums in rust behave like a tagged union. That means the size of each variant
is equal to the size of the biggest field + an enum tag.

The largest field in our byte code representation is the Jz label. It contains
a String and an i32.

\begin{verbatim}
A string in Rust contains:
    8 bits -> pointer to the chars
    8 bits -> len of the string
    4 bits -> the i32 value
    8 bits -> enum tag
    + padding

    adds up to 32 bits.
\end{verbatim}

This decision might be good for developing since the Rust compiler will warn 
if you for example forget a variant in a match statement but it is not really
efficient.

\subsection{Interpreter}
The interpreter consists of a scanner and a parser. We have decided to
handwrite both parts instead of generating them. Even though the scanner and
the parser are not the most performance critical parts of an interpreter we
decided to handwrite them in Rust.

\subsubsection{Scanner}
The scanner was implemented very straight forward by using a match statement 
to iterate the source code and output a stream of tokens.

Tokens are defined as the token type and an optional literal.

\begin{verbatim}
pub struct Token {
    pub token_type: TokenType,
    pub literal: Option<Object>,
}
\end{verbatim}
\textit{Token definition}

\begin{verbatim}
pub enum Object {
    Num(f64),
    Bool(bool),
    Variable(String),
    DivByZeroError,
    ArithmeticError,
}
\end{verbatim}
\textit{Object definition}

\begin{verbatim}
pub enum TokenType {
    LeftParen,
    RightParen,

    Minus,
    Plus,
    ...
    Eof,
}
\end{verbatim}
\textit{TokenType definition}

\subsubsection{Parser}
The parser takes the stream of tokens as input and builds up an abstract syntax
tree. In the Rust code it is represented as a `Vec<Rc<Stmt>>`.

\begin{verbatim}
As an example the code `x := 10;` will get tokenized into 
`[Identifier,Assignment, NumberLiteral, Semicolon]` 
and the parser will output a tree structure like:

ExpressionStmt {
    expr: AssignExpr {
        name: "x",
        value: LiteralExpr {
            value: Num(10)
        }
    }
}
\end{verbatim}


\subsubsection{Interpreter (testing)}
To be able to test the scanner and parser before writing the bytecode generator
we build a small interpreter that just runs the code.

It uses the visitor pattern to traverse the abstract syntax tree generated by
the parser and executes the code immediatly.

To use the visitor pattern approach we implemented a statement visitor and an
expression visitor.

\begin{verbatim}
pub trait StmtVisitor<T> {
    fn visit_block_stmt(&self, stmt: &BlockStmt) -> Result<T, ()>;
    fn visit_if_stmt(&self, stmt: &IfStmt) -> Result<T, ()>;
    fn visit_expression_stmt(&self, stmt: &ExpressionStmt) -> Result<T, ()>;
    fn visit_print_stmt(&self, stmt: &PrintStmt) -> Result<T, ()>;
    fn visit_while_stmt(&self, stmt: &WhileStmt) -> Result<T, ()>;
}
\end{verbatim}
\textit{Statement visitor example}

For each statement we have setup a structure holding the necessary data.

\begin{verbatim}
#[derive(Debug)]
pub struct IfStmt {
    pub condition: Rc<Expr>,
    pub then_branch: Rc<Stmt>,
    pub else_branch: Option<Rc<Stmt>>,
}
\end{verbatim}
\textit{Structure holding data for an if statement}


\subsection{Optimizations} % explaination of the optimizations
Optimizaions play a critical role in the field of compiler design. There are many
ways to optimize code.

Some common techniques are:
\begin{enumerate}
    \item \textbf{Dead Code Elimination}:\\
        Remove parts of the code that are never to be used.

        Consider the follwing C code. In this case the variable `c` is never
        used so the statement `int c = 3;` does not need to be compiled
        \begin{verbatim}
        int main() {
            int a = 1;
            int b = 2;
            int c = 3; // never used

            return a + b;
        }
        \end{verbatim}
    \item \textbf{Constant folding}:\\
        When calcualtions are only using constant values and by that can be
        evaluated during compile time it will directly replace it with the
        computed value.

        Consider the follwing C code. In this example `int a = 10 + 20;` only uses values known
        at compile time so the compiler can internally replace the statement with `int a = 30;`.
        \begin{verbatim}
        int main() {
            int a = 10 + 20;
            printf("%d", a);

            return 0;
        }
        \end{verbatim}
    \item \textbf{Superinstructions}:\\
        Superinstructions is a term used for the case when combining two or more instructions 
        into a single big instruction.

        Consider the following C code.

        \begin{verbatim}
        int main() {
            int i = 0;
            while (i < 10) {
                i += 1;
            }
        }
        \end{verbatim}

        If we naively 'compile' this code we would get instructions like this:

        \begin{verbatim}

        // in the loop
        load i -- get the variable at i and push it to the stack
        push 1 -- push the value '1' to the stack
        add    -- pop the first 2 values from the stack, add them, and push the result back on the stack

        \end{verbatim}

        We always need 2 instructions to push the constant value to the stack and then add the top
        2 values on the stack together.

        But we can create a superinstruction called 'push\_add' which would change the generated
        code to this.

        \begin{verbatim}

        // in the loop
        load i     -- get the variable at i and push it to the stack
        push_add 1 -- superinstruction that does the push and then the add

        \end{verbatim}

        That change might seem very insignificant but we can extend this idea
        of superinstructions to combine already built superinstructions with
        each other and by that save many instructions.


    \item \textbf{Computed goto}:\\
    \label{it:goto}
        When executing the bytecode inside of a virtual machine interpreter for
        example you will usually find a big switch statement inspecting the
        current instruction and executing it. In our case, since we used Rust
        we have a big match statement like this.

        \begin{verbatim}

        while self.pc < instructions.len() as i32 {
            let inst = &instructions[self.pc as usize];
            match inst {
                ByteCode::Push(value) => {
                    self.stack.push(*value);
                }
                ByteCode::Pop => {
                    self.stack.pop().unwrap();
                }
                ByteCode::Add => {
                    let a = self.stack.pop().unwrap();
                    let b = self.stack.pop().unwrap();
                    self.stack.push(b + a);
                }
                ...
            }
        }
        \end{verbatim}

        This `while` loop will iterate over every single instruction in the program. That means
        for every instruction it has to go through all the possible values inside of the `match`
        statement until it find the matching result.

        The `Computed goto` optimization tries to make this process more efficient.

        To implement that, we have to create an array of function pointers where
        the index of the array corresponds to an instruction or use a HashMap
        with the byte code instruction as the key and the function as a value
        like we did in Rust.

        \begin{verbatim}

        pub type Instruction = fn(interp: &mut ByteCodeInterpreterThreaded);
        ... {
            ops: HashMap<Discriminant<ByteCode>, Instruction>
        }

        ops.insert(std::mem::discriminant(&ByteCode::Push(0)), Self::op_push);
        ops.insert(std::mem::discriminant(&ByteCode::Pop), Self::op_pop);
        ops.insert(std::mem::discriminant(&ByteCode::Add), Self::op_add);
        \end{verbatim}

        Then each of the functions (Self::op\_push, Self::op\_add, ...) will finish
        with a call to a `next()` function.

        This next() function will increment the program counter (the index of
        where we are in the byte code) and call the function which was mapped
        to the next instruction in the HashMap.

        In our case in Rust the next function looks like the following.

        \begin{verbatim}
        fn next(&mut self) {
            // incrementing the program counter;
            self.pc += 1 

            // check for end of stream
            if self.pc >= self.instructions.len() as i32 {
                return; 
            }

            // call the next function
            self.ops[&self.instructions[self.pc as usize]](self);
        }
        \end{verbatim}

        This threaded code approach results in a short and fast instruction
        dispatch sequence and can lead to better branch prediction accuracy on
        machines with branch target buffers as stated by the authors of vmgen ~\cite{vmgen}.

\end{enumerate}

\subsection{Input language} % talk about imp
\label{sec:input_language}
When you want to build a virtual machine interpreter you need to have an
input language. Instead of creating our own programming language for this
project we chose the programming language Imp. ~\cite{Pierce:SF1}

"Imp is a simple imperative programming language which embodies a tiny core
fragment of conventional mainstream languages such as C or Java". ~\cite{Pierce:SF1}

\begin{verbatim}
    Z := X;
    Y := 1;
    while Z != 0 do
        Y := Y * Z;
        Z := Z - 1;
    end
\end{verbatim}
\textit{Example code in the Imp programming language} \\

Not only is Imp simple but it is already fully defined and has many examples
we can test agains.

The book `IMP Simple Imperative Programs` by Benjamin C. Pierce
~\cite{Pierce:SF1} describes the language in detail and provides for example
BNF grammar definitions of the syntax which makes it easy understandable and
provides a guideline when developing the scanner and parser of the interpreter.

The language has no scope so all variables are global. This fact makes it easier
for us since we do not need to keep track of scopes or environments and the
variable lookup in our interpreter is just one single HashMap that holds all 
global variables.

Variables can be assigned without the need to give an explicit type since all
the variables in Imp are numbers. Again this makes it very convinient for us to
implement.

\begin{verbatim}
    a := 1;
    b := a;
\end{verbatim}
\textit{Variable assignment in the Imp programming language} \\

Imp defines while loops which are delimited by the `do` and `end` keyword and
do not need any parentheses around the condition. Those particular circumstances
makes it easy to parse.

\begin{verbatim}
    a := 0;
    while a < 10 do
        a := a + 1;
    end
\end{verbatim}
\textit{While statement in the Imp programming language} \\

Similar to while loops, if statements are also defined without any unnecessary
parentheses and it is delimited with describing keywords like `then`, `else`
and `end`.

\begin{verbatim}
    a := 0;
    if a < 10 then
        a := a + 1;
    end
\end{verbatim}
\textit{If statement in the Imp programming language} \\

For convinience and testing purposes we added our own keyword `print` to the
language. It helps during development to get a better view into the execution
of the interpreter.

\begin{verbatim}
    a := 0;
    if a < 10 then
        print a + 1;
    else
        print a - 1;
    end
\end{verbatim}
\textit{Print statement in the Imp programming language} \\

Imp does not include function calls or any of the commonly known features of
todays high level languages such as classes, lambdas, structs or even strings
and arrays.

\clearpage
\bibliographystyle{plain}
\bibliography{dissertation}
\end{document}

%what to do?
%write test programs, find superinstructions, do benchmarks, mandelbrot
%format of dis

